# Práctica 2 CCII: Despliegue de Contenedores con Kubernetes y OpenFaaS

## Descripción

En esta práctica se aborda el despliegue de contenedores utilizando **Kubernetes** con **Minikube** y **OpenFaaS** para implementar funciones serverless. El objetivo principal es configurar un entorno funcional que permita ejecutar funciones serverless y procesar imágenes codificadas en base64. Este despliegue se ha realizado en el servidor de galeon proporcionado en esta asignatura.

---

## Pasos Realizados

## 1. Inicialización de Minikube

Se inicia Minikube con el siguiente comando, utilizando el driver Docker y el runtime `containerd`:

```bash
minikube start --driver=docker --container-runtime=containerd
```

## 2. Configuración del Entorno Kubernetes
Se establece un port-forwarding para exponer el gateway de OpenFaaS en el servidor elegimos el puerto reservado para nosotros en mi caso el 20260:

``` bash
minikube tunnel --bind-address=0.0.0.0 &
kubectl port-forward -n openfaas --address 0.0.0.0 svc/gateway 20260:8080 &
```

Al verificar inicialmente los recursos en el namespace de OpenFaaS, observamos que aún no estaban desplegados:
```
kubectl get svc -n openfaas
kubectl get deploy -n openfaas
```
Ambos comandos indicaron que no había recursos disponibles.

Confirmamos que los namespaces OpenFaaS y OpenFaaS-fn se encontraban activos:
```bash 
kubectl get ns
```
por lo me hizo plantear la siguiente solución
## 3. Instalación de Helm
Inicialmente, intentamos instalar Helm mediante el script proporcionado en la documentación oficial, pero encontramos problemas debido a la falta de permisos sudo.

Como alternativa, descargamos e instalamos Helm localmente:
```bash
curl -LO https://get.helm.sh/helm-v3.17.3-linux-amd64.tar.gz
tar -zxvf helm-v3.17.3-linux-amd64.tar.gz
mkdir -p $HOME/bin
mv linux-amd64/helm $HOME/bin/
export PATH=$HOME/bin:$PATH
source ~/.bashrc
helm version
```
Confirmamos la instalación exitosa de Helm.

## 4. Instalación de OpenFaaS

Añadimos el repositorio de OpenFaaS y actualizamos los repositorios locales de Helm:

 ``` bash
 helm repo add openfaas
https://openfaas.github.io/faas-netes/
helm repo update
``` 

Desplegamos OpenFaaS con la siguiente configuración:
```bash
helm install openfaas --namespace openfaas openfaas/openfaas --set functionNamespace=openfaas-fn --set basic_auth=false
```
Tras la instalación, revisamos el estado de los pods y servicios:
```
kubectl get pods -n openfaas
kubectl get svc -n openfaas
```
Confirmamos que todos los pods y servicios necesarios quedaron activos correctamente.

Finalmente, establecemos la variable de entorno para acceder al gateway de OpenFaaS:
```
export OPENFAAS_URL=http://127.0.0.1:20260
```
Si vamos a http://galeon.ugr.es:20260/ui/ podemos ver como se puede acceder al servicio de OpenFaas.
![OpenFaas](/P2/images/Openfaas.png) 
## 5. Intalación y creación del detector facial.
Para implementar el detector facial, realizaremos el despliegue de una solución personalizada, aunque existen alternativas predefinidas como la función `face-detect-pigo` disponible en el store de OpenFaaS mediante el comando:
```bash
faas-cli store deploy face-detect-pigo
```
Sin embargo, en este caso, crearemos nuestra propia función personalizada utilizando el siguiente comando:
```bash
faas-cli new --lang python3-http facesdetection-python
```

Esto generará una estructura de directorios con los siguientes archivos:
```bash
facedetection$ tree
.
├── facesdetection-python
│   ├── handler.py
│   ├── handler_test.py
│   ├── requirements.txt
│   └── tox.ini
├── stack.yaml
└── template
    └── python3-http
        ├── Dockerfile
        ├── function
        │   ├── handler.py
        │   ├── handler_test.py
        │   ├── requirements
        │   ├── requirements.txt
        │   └── tox.ini
        ├── index.py
        ├── requirements.txt
        └── template.yml
```

El archivo **handler.py** generado inicialmente contiene el siguiente código base:
```python
 def handle(event, context):
    return {
        "statusCode": 200,
        "body": "Hello from OpenFaaS!"
    }
```
Este código será modificado para implementar la lógica del detector facial. Y vamos a cambiarlo por el siguiente : 
```python
#!/usr/bin/env python
import cv2
import numpy as np
import requests
import base64
import sys

def download_image(url):
    """Descarga la imagen y la decodifica con OpenCV."""
    print("[DEBUG] Descargando imagen desde URL:", url, file=sys.stderr)
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        image_array = np.frombuffer(response.content, np.uint8)
        image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)
        if image is None:
            raise ValueError("No se pudo decodificar la imagen; revisa el formato.")       
        print("[DEBUG] Imagen descargada y decodificada correctamente", file=sys.stderr)   
        return image
    except Exception as e:
        raise Exception(f"Error descargando la imagen: {e}")

def detect_faces(image):
    """Detecta rostros en la imagen usando el clasificador Haar de OpenCV."""
    print("[DEBUG] Iniciando detección de rostros", file=sys.stderr)
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)
    print(f"[DEBUG] Detección finalizada, rostros encontrados: {len(faces)}", file=sys.stderr)
    return faces

def draw_faces(image, faces):
    """Dibuja rectángulos en los rostros detectados."""
    print("[DEBUG] Dibujando recuadros en los rostros", file=sys.stderr)
    for (x, y, w, h) in faces:
        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)
    print("[DEBUG] Recuadros dibujados correctamente", file=sys.stderr)
    return image

def image_to_base64(image):
    """Convierte la imagen procesada a una cadena en Base64."""
    print("[DEBUG] Codificando imagen a Base64", file=sys.stderr)
    ret, buffer = cv2.imencode('.png', image)
    if not ret:
        raise Exception("Error al codificar la imagen.")
    encoded = base64.b64encode(buffer).decode('utf-8')
    print(f"[DEBUG] Imagen codificada a Base64, longitud: {len(encoded)} caracteres", file=sys.stderr)
    return encoded

def handle(event, context):
    """Función que se invoca con el evento y el contexto.

    Se espera que el body del evento contenga la URL de la imagen.
    """
    try:
        print("[DEBUG] Iniciando handle en handler.py", file=sys.stderr)

        # Convertir el cuerpo a string si es bytes
        if isinstance(event.body, bytes):
            body_str = event.body.decode('utf-8')
        else:
            body_str = event.body

        url = body_str.strip()
        print(f"[DEBUG] Contenido del body: {url}", file=sys.stderr)

        if not url:
            return { "statusCode": 400, "body": "No se proporcionó una URL en la solicitud." }

        image = download_image(url)
        faces = detect_faces(image)
        image_with_faces = draw_faces(image, faces)
        encoded_image = image_to_base64(image_with_faces)

        print("[DEBUG] Handler finalizando correctamente", file=sys.stderr)
        return {
            "statusCode": 200,
            "headers": {"Content-Type": "application/json"},
            "body": encoded_image
        }
    except Exception as e:
        error_message = f"Error durante la detección de rostros: {str(e)}"
        print(f"[DEBUG] {error_message}", file=sys.stderr)
        return { "statusCode": 500, "body": error_message }
```
Además, actualizaremos el archivo index.py para que sea coherente con los cambios realizados en el handler.py.
```bash
#!/usr/bin/env python
from flask import Flask, Response, jsonify, request
from waitress import serve
import os
import sys

from function import handler

app = Flask(__name__)

class Event:
    def __init__(self):
        print("[DEBUG] Creando objeto Event", file=sys.stderr)
        self.body = request.get_data()  # Captura los datos crudos del request
        self.headers = request.headers
        self.method = request.method
        self.query = request.args
        self.path = request.path
        print(f"[DEBUG] Event creado con body de longitud: {len(self.body)}", file=sys.stderr)

class Context:
    def __init__(self):
        self.hostname = os.getenv('HOSTNAME', 'localhost')
        print(f"[DEBUG] Context creado, hostname: {self.hostname}", file=sys.stderr)       

def format_response(resp):
    if resp is None:
        return ('', 200)
    if isinstance(resp, dict):
        status = resp.get("statusCode", 200)
        body = resp.get("body", "")
        headers = resp.get("headers", {})
        # Si el cuerpo es bytes, devuélvelo directamente en una respuesta binaria
        if isinstance(body, bytes):
            return Response(body, status=status, headers=headers)
        else:
            return (jsonify(body), status, headers)
    return resp

@app.route('/', defaults={'path': ''}, methods=['GET', 'PUT', 'POST', 'PATCH', 'DELETE'])  
@app.route('/<path:path>', methods=['GET', 'PUT', 'POST', 'PATCH', 'DELETE'])
def call_handler(path):
    print("[DEBUG] Invocación de call_handler en index.py", file=sys.stderr)
    event = Event()
    context = Context()
    print("[DEBUG] Llamando a handler.handle", file=sys.stderr)
    response_data = handler.handle(event, context)
    print("[DEBUG] Respuesta obtenida. Procesando respuesta...", file=sys.stderr)
    return format_response(response_data)

if __name__ == '__main__':
    print("[DEBUG] Iniciando servidor con Waitress", file=sys.stderr)
    serve(app, host='0.0.0.0', port=5000)
```
Y fianlmente actualizamos los requirements.

NOTA es importante tambien que el handler dentro de templates sea similar al de la carpeta /facesdetection-python

Adicionalmente configuraremos el dockerfile para que tenga en cuenta las nuevas importaciones necesarias
```
ARG PYTHON_VERSION=3.12 
FROM --platform=${TARGETPLATFORM:-linux/amd64} ghcr.io/openfaas/of-watchdog:0.10.7 AS watchdog
FROM --platform=${TARGETPLATFORM:-linux/amd64} python:${PYTHON_VERSION}-slim AS build      

# Copia el watchdog desde la etapa anterior y hazlo ejecutable
COPY --from=watchdog /fwatchdog /usr/bin/fwatchdog
RUN chmod +x /usr/bin/fwatchdog

ARG UPGRADE_PACKAGES
ARG ADDITIONAL_PACKAGE

# Actualiza el sistema e instala paquetes usando apt-get, añadiendo libgl1
RUN if [ "${UPGRADE_PACKAGES}" = "true" ] || [ "${UPGRADE_PACKAGES}" = "1" ]; then \       
      apt-get update && apt-get upgrade -y; \
    fi && \
    apt-get update && apt-get install -y libgl1  libglib2.0-0 ${ADDITIONAL_PACKAGE} && rm -rf /var/lib/apt/lists/*

# Agrega el usuario "app" y crea su directorio home (-m crea /home/app)
RUN groupadd -r app && useradd -m -r -g app app

USER app

ENV PATH=$PATH:/home/app/.local/bin

WORKDIR /home/app/

# Copia archivos base
COPY --chown=app:app index.py           .
COPY --chown=app:app requirements.txt   .

USER root
RUN pip install --no-cache-dir -r requirements.txt

# Construye el directorio de la función e instala componentes específicos del usuario      
USER app
RUN mkdir -p function
RUN touch ./function/__init__.py
WORKDIR /home/app/function/
COPY --chown=app:app function/requirements.txt  .
RUN pip install --no-cache-dir --user -r requirements.txt

# Copia el código de la función
USER root
COPY --chown=app:app function/   .

FROM build AS test
ARG TEST_COMMAND=tox
ARG TEST_ENABLED=true
RUN [ "$TEST_ENABLED" = "false" ] && echo "skipping tests" || eval "$TEST_COMMAND"

FROM build AS ship
WORKDIR /home/app/

# Configura el servidor WSGI y healthcheck
USER app
ENV fprocess="python index.py"
ENV cgi_headers="true"
ENV mode="http"
ENV upstream_url="http://127.0.0.1:5000"

HEALTHCHECK --interval=5s CMD [ -e /tmp/.lock ] || exit 1

CMD ["fwatchdog"]
```
y finalmente actualizamos el stack.yaml para que se suba la imagen generada a DockerHub y posteriormente sea usada en nuestro despliegue.
```yaml 
version: 1.0
provider:
  name: openfaas
  gateway: http://127.0.0.1:20260
functions:
  facesdetection-python:
    lang: python3-http
    handler: ./facesdetection-python
    image: adrianoggm10/facesdetection-python:latest

```
Cerrando así la configuración de los contenedores y servicio.
## 6. Despliegue y uso del servicio Facial recognition
A continuación  ejecutamos: 
```bash 
faas-cli up -f stack.yaml
```
Podemos ver mientras que se ejecuta que en nuestro dockerhub aparece la imagen del contenedor que hemos configurado.
![Dockerhub](/P2/images/dockerhubimage.png)
Después de unos momentos, podemos verificar que en la interfaz de OpenFaaS, accesible desde [http://galeon.ugr.es:20260/ui/](http://galeon.ugr.es:20260/ui/), aparece nuestra nueva función desplegada y en estado "Ready":

![OpenFaas2](/P2/images/Openfaas2.png)

Con la función activa, procedemos a realizar una prueba enviando una solicitud HTTP POST para procesar una imagen. Utilizamos el siguiente comando `curl` para enviar la URL de la imagen que deseamos analizar:

```bash
curl -v -X POST -d "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSCdio_Sf9aON6NjLHo5fXjG1HNZzWCaTsUjQ" http://127.0.0.1:20260/function/facesdetection-python -o respuesta.txt
```
https://www.solidarios.org.es/wp-content/uploads/2023/06/Mayores-20161.jpg
Esta solicitud envía la URL de la imagen al servicio, que realiza el reconocimiento facial sobre la siguiente imagen de prueba:
![Original](/P2/images/original.jpg) 

El resultado de la función será una imagen procesada, codificada en formato Base64, que se almacena en el archivo respuesta.txt. Para convertir este resultado en una imagen visible, seguimos los pasos a continuación:

Limpiamos el archivo respuesta.txt para eliminar las comillas iniciales y finales del string Base64:
``` bash
sed 's/^"//;s/"$//' respuesta.txt > respuesta_clean.txt
```
Decodificamos el string Base64 y generamos la imagen final:
```bash
adrianoggm@galeon:~/facedetection$ base64 -d respuesta_clean.txt > imagen.png
```
Al finalizar obtendremos la imagen final con 9 personas reconocidas.

![Reconocida](/P2/images/imagen.png) 